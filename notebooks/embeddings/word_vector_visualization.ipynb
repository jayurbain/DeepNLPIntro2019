{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "ml-qa",
      "language": "python",
      "name": "ml-qa"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "word_vector_visualization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCNAcBM7f1-4",
        "colab_type": "text"
      },
      "source": [
        "### Word vector visualization \n",
        "\n",
        "Jay Urbain, PhD\n",
        "\n",
        "Word vector visualization with [Gensim](https://github.com/RaRe-Technologies/gensim)\n",
        "\n",
        "Credits:  \n",
        "https://www.machinelearningplus.com/nlp/gensim-tutorial/  \n",
        "https://radimrehurek.com/gensim/downloader.html   \n",
        "[Stanford Class CS224b](https://web.stanford.edu/class/cs224n/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn6AQl7Qf1-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Matplotlib for plotting\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# sklearn for PCA dimensionality reduction\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Gensim for word vectors\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxEepkbtf1-7",
        "colab_type": "text"
      },
      "source": [
        "Gensim is an NLP library that is especially handy for working with word vectors. Gensim isn't really a deep learning package. It's a package for  word and text similarity modeling, which started with LDA-style [Latent Dirichlet Allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)  topic models and grew into SVD [Singular Value Decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) and neural word representation library. But its efficient, scalable, and widely used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVp35Md2f1-8",
        "colab_type": "text"
      },
      "source": [
        "You can try *50d, *100d, *200d, or *300d vectors. Research efforts have shown that performance does not improve with vectors larger than 300d."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke1b4T26f1-8",
        "colab_type": "text"
      },
      "source": [
        "#### Download\n",
        "\n",
        "We can download and evaluate fasttext, word2vec, and glove models using the `gensim.downloader api`. These are large files, so you will have to be a little patient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9SeQE7xf1-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "#print( api.info() )  # return dict with info about available models/datasets\n",
        "print( api.info(\"text8\") )  # return dict with info about \"text8\" dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP0s_xY1f1_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load(\"glove-twitter-25\")  # load glove vectors\n",
        "model.most_similar(\"cat\")  # show words that similar to word 'cat'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-626MJof1_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Download the models\n",
        "# fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')\n",
        "# word2vec_model300 = api.load('word2vec-google-news-300')\n",
        "glove_model300 = api.load('glove-wiki-gigaword-300')\n",
        "\n",
        "# Get word embeddings\n",
        "glove_model300.most_similar('support')\n",
        "# [('supporting', 0.6251285076141357),\n",
        "#  ...\n",
        "#  ('backing', 0.6007589101791382),\n",
        "#  ('supports', 0.5269277691841125),\n",
        "#  ('assistance', 0.520713746547699),\n",
        "#  ('supportive', 0.5110025405883789)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGEWSTjqf1_I",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluation\n",
        "\n",
        "To run the following code, set `model` to the model you would like to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVbSglvff1_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = glove_model300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug_QCp2Sf1_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.most_similar('obama')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3wlxTB7f1_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.most_similar('banana')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YewznyH7f1_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.most_similar(negative='banana')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWlzBzjcf1_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"{}: {:.4f}\".format(*result[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRLQCcQLf1_X",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "  **Visualizing word vectors - blog.acolyer.org**  \n",
        "\n",
        "<img src=\"https://adriancolyer.files.wordpress.com/2016/04/word2vec-king-queen-vectors.png?w=400\"/>\n",
        "\n",
        "\n",
        "**word2vec King - Queen Composition - blog.acolyer.org**\n",
        "\n",
        "<img src=\"https://adriancolyer.files.wordpress.com/2016/04/word2vec-king-queen-composition.png\" width=\"400px\"/>\n",
        "\n",
        "**The Illustrated Word2Vec - Jay Alamar** \n",
        "\n",
        "<img src=\"http://jalammar.github.io/images/word2vec/king-analogy-viz.png\" width=\"400px\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8qhIMaNf1_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x1 is to x2 as y1 is to ?\n",
        "def analogy(x1, x2, y1):\n",
        "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
        "    return result[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY2pPMO_f1_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analogy('japan', 'japanese', 'australia')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfGDry_Af1_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analogy('australia', 'beer', 'france')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRfOcRDFf1_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analogy('obama', 'clinton', 'reagan')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNAokpHRf1_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analogy('tall', 'tallest', 'long')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NozRhZ4Xf1_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analogy('good', 'fantastic', 'bad')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJl585URf1_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bweMqPjgf1_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "def display_pca_scatterplot(model, words=None, sample=0):\n",
        "    if words == None:\n",
        "        if sample > 0:\n",
        "            words = np.random.choice(list(model.vocab.keys()), sample)\n",
        "        else:\n",
        "            words = [ word for word in model.vocab ]\n",
        "        \n",
        "    word_vectors = np.array([model[w] for w in words])\n",
        "\n",
        "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
        "    \n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
        "    for word, (x,y) in zip(words, twodim):\n",
        "        plt.text(x+0.05, y+0.05, word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YPLTsp4f1_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_pca_scatterplot(model, \n",
        "                        ['coffee', 'tea', 'beer', 'wine', 'brandy', 'rum', 'champagne', 'water',\n",
        "                         'spaghetti', 'borscht', 'hamburger', 'pizza', 'falafel', 'sushi', 'meatballs',\n",
        "                         'dog', 'horse', 'cat', 'monkey', 'parrot', 'koala', 'lizard',\n",
        "                         'frog', 'toad', 'monkey', 'ape', 'kangaroo', 'wombat', 'wolf',\n",
        "                         'france', 'germany', 'hungary', 'luxembourg', 'australia', 'fiji', 'china',\n",
        "                         'homework', 'assignment', 'problem', 'exam', 'test', 'class',\n",
        "                         'school', 'college', 'university', 'institute'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Zexja0avf1_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_pca_scatterplot(model, sample=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuJ0O0ogf1_1",
        "colab_type": "text"
      },
      "source": [
        "#### To do: explore some concepts on your own.\n",
        "\n",
        "I've started looking at medical concepts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oEScQbaf1_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.most_similar('cardiac')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f5QAzemf1_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.most_similar('diabetes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj7u4qDmf1_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.most_similar('opioid', topn=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6rO0HJTf1__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.most_similar('alzheimers', topn=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSGIZBDYf2AB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analogy('endocrine', 'diabetes', 'neural')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqqbYJ2Pf2AD",
        "colab_type": "text"
      },
      "source": [
        "#### Summary\n",
        "\n",
        "We've explored the concepts of learned word representations. In so doing, we identified semantic relationshiops between word vectors.\n",
        "\n",
        "A significant disadvantage of word2vec, Glove, and fasttest is that they are `context free` word representations, i.e., the only represent each word with a single vector and do not take context into account.\n",
        "\n",
        "A more advanced tutorial can be found here:  \n",
        "    https://github.com/sismetanin/word2vec-tsne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXgKl1M1f2AD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}